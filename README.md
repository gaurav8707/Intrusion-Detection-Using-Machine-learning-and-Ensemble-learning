# Intrusion-Detection-Using-Machine-learning-and-Ensemble-learning

Members:

Gaurav Sharan (20MIA1081)
Shashank Pandey(20MIA1147)
Jalavadi Shree Nikhila (20MIA1023)
Atul Patel(20MIA1134)
Pratyansh Soni (20MIA1084)

Intrusion Detection using ML and Ensemble Learning

In today's era, data is considered one of the most valuable assets, and it is critical to protect it from potential cyber threats and attacks. Intrusion Detection System (IDS) is a security solution that helps in detecting potential threats and attacks in real-time. IDS monitors network traffic, system activities, and user behavior, and alerts security personnel about any suspicious activity.
With the advancement in technology and the rise in cyber-attacks, predictive analysis has become an essential tool for IDS. Predictive analysis involves using statistical techniQues, Machine Learning algorithms, and Artificial Intelligence to analyze historical data and predict future events.
IDS is a critical component of cybersecurity, and predictive analysis can significantly improve its effectiveness. By analyzing historical data and predicting potential threats, IDS can become more proactive and effective in detecting potential threats and attacks. With this presentation, we aim to provide you with an understanding of how predictive analysis can enhance IDS and help organizations better protect their data and assets.

About

This repo contanins the IPYNB Files and the project report. 
For Running these codes on your computer you need to install the neccessary python libraries such as numpy , pandas and tensorflow.
The methodology used in the project are -
I.	Data Collection: Collecting data from various sources, such as network traffic, system logs, and application logs, is the first step in the IDS methodology. The quality and quantity of data collected have a significant impact on the accuracy of predictive analytics.
![image](https://user-images.githubusercontent.com/91775940/233415162-39c61954-9818-4e61-a3a5-99b4b043bfa2.png)



II.	Data Pre-processing: After collecting the data, it is pre-processed to remove noise and irrelevant information. Data pre-processing techniques such as data cleaning, normalization, and feature selection are applied to ensure that the data is of high quality and relevant to the analysis.

III.	Feature Engineering: Feature engineering involves identifying the most relevant features or attributes that can contribute to the prediction of potential threats and attacks. This step is critical to improving the accuracy of predictive analytics in IDS.

IV.	Model Building: Once the relevant features are identified, various predictive analytics techniques such as clustering, classification, and anomaly detection are applied to build a predictive model. The model is trained on historical data to identify patterns and predict potential threats and attacks.

V.	Model Evaluation: The effectiveness of the predictive model is evaluated using various metrics such as accuracy, precision, recall, and F1 score. The model may need to be fine-tuned and optimized to improve its accuracy.

VI.	Deployment: After building and evaluating the predictive model, it is deployed in the production environment, where it continuously monitors the network for potential threats and attacks. Any alerts generated by the model are analyzed by human experts and appropriate action is taken to mitigate the threat.

The algorithm Used in our project are :
Machine learning Algorithms
1.Logistic regression
2.SVM(Support Vector Machines)
3.XGBoost

Deep learing
1.CNN
2.Hybrid Model(CNN+RNN)

Results and inferences

1. Logistic Regression

After performing Simple Logistic Regression we got an accuracy of 97.5627806816
For improving this accuracy we tried to perform K fold Cross validation(K-fold Cross-Validation is when the dataset is split into a K number of folds and is used to evaluate the model's ability when given new data)
After performing K fold cross validation we got an accuracy of 98.6742139215 . So we can see that the accuracy increased after K fold cross validation.

2. SVM
After performing the simple SVM we got an accuracy of 89.9067863719 , then we performed K fold cross validation then we achieved the accuracy of almost 92%

For increasing this accuracy we did Hyper-parameter Tuning(The grid search)Grid search is the simplest algorithm for hyperparameter tuning. Basically, we divide the domain of the hyperparameters into a discrete grid. Then, we try every combination of values of this grid, calculating some performance metrics using cross-validation. After performing the grid search we got the best accuracy among all models and it was 99.7370369592 .
These were the best parameters best params: {'C': 10, 'gamma': 0.1}



3. XGboost
After performing Only XGboost we got an accuracy of around 62% . 
For increasing this accuracy we performed hyper -parameter tuning , after performing almost 5 test models ww got an accuracy of 90% which was the huge increase from 62%.

Results of various Parameter tuned models 
Base model 0:  61.75 %
Test model 1:  81.89 %
Test model 2:  72.12 %
Test model 3:  67.01 %
Test model 4:  81.89 %
Test model 5:  90.49 %
So after hyperparameter tuning, Accuracy has increased from 61.75% to 90.49%.


4.CNN
After training the Simple CNN model we got an accuracy of 52.52%


5.Hybrid Model(CNN+RNN)

After concatenating
 the CNN and RNN model we got an accuracy of around 52%.
 
 
Logistic Regression :98.6742139215%
Support Vector Machines :99.7370369592%
XGBoost Classifier: 90.49%.
CNN:52.52%
Hybrid model :52.38%


So hereby we can conclude that SVM(Support Vector machines) performed best among all other algorithms with an accuracy of 99.737%






